# Shared base configuration for all BoltzKinema training phases.
#
# Phase-specific configs override values from this file.
# Usage:
#   accelerate launch scripts/train.py --base-config configs/base.yaml --config configs/train_phase0.yaml

# === Model ===
token_s: 384
token_z: 128
atom_s: 128
atom_z: 16
atom_feature_dim: 128
atoms_per_window_queries: 32
atoms_per_window_keys: 128
sigma_data: 16.0
dim_fourier: 256
atom_encoder_depth: 3
atom_encoder_heads: 4
atom_temporal_heads: 4
token_transformer_depth: 24
token_transformer_heads: 16
token_temporal_heads: 16
atom_decoder_depth: 3
atom_decoder_heads: 4
conditioning_transition_layers: 2
activation_checkpointing: true
freeze_diffusion_conditioning: false

# === Shared training params ===
max_epochs: 1000
batch_size_per_gpu: 1
gradient_accumulation_steps: 4
grad_clip: 10.0
seed: 42
n_frames: 32
P_mean: -1.2
P_std: 1.5
forecast_prob: 0.5
num_workers: 4

# === Loss ===
alpha_bond: 1.0
beta_flex: 1.0
beta_abs: 1.0
beta_rel_g: 4.0
beta_rel_l: 4.0
beta_center: 1.0
mol_weights:
  protein: 1.0
  dna: 5.0
  rna: 5.0
  ligand: 10.0

# === Paths ===
boltz2_checkpoint: ~/.boltz/boltz2_conf.ckpt
manifest_path: data/processed/manifest.json
trunk_cache_dir: data/processed/trunk_embeddings/  # optional fallback if manifest trunk paths are missing
coords_dir: data/processed/coords/  # optional fallback root if manifest coords paths are missing
log_every: 50
save_every: 5000
